{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc617c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install requests beautifulsoup4 fpdf html2text weasyprint reportlab -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843513f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.enums import TA_CENTER, TA_LEFT\n",
    "from reportlab.lib.units import mm\n",
    "import textwrap\n",
    "import os\n",
    "\n",
    "def create_clean_pdf(url):\n",
    "    # 1️⃣ Fetch webpage\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    html = response.text\n",
    "\n",
    "    # 2️⃣ Extract main content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Try to get title and main text content\n",
    "    title = soup.title.string.strip() if soup.title else \"Webpage Content\"\n",
    "    main_content = soup.find(\"main\") or soup.find(\"article\") or soup.body\n",
    "    if not main_content:\n",
    "        main_content = soup\n",
    "\n",
    "    # Remove scripts, styles, and nav\n",
    "    for tag in main_content.find_all([\"script\", \"style\", \"nav\", \"footer\", \"header\", \"noscript\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    text_parts = []\n",
    "    for elem in main_content.find_all([\"h1\", \"h2\", \"h3\", \"p\", \"li\"]):\n",
    "        txt = elem.get_text(strip=True)\n",
    "        if txt:\n",
    "            text_parts.append(txt)\n",
    "    clean_text = \"\\n\\n\".join(text_parts)\n",
    "\n",
    "    # 3️⃣ Create PDF filename\n",
    "    os.makedirs(\"webpage_pdfs\", exist_ok=True)\n",
    "    name = url.split(\"/\")[-1] or \"index\"\n",
    "    pdf_path = os.path.join(\"webpage_pdfs\", f\"{name}.pdf\")\n",
    "\n",
    "    # 4️⃣ Format & write PDF (same style as your AI Supply Chain PDF)\n",
    "    doc = SimpleDocTemplate(pdf_path, pagesize=A4,\n",
    "                            rightMargin=20*mm, leftMargin=20*mm,\n",
    "                            topMargin=20*mm, bottomMargin=20*mm)\n",
    "\n",
    "    styles = getSampleStyleSheet()\n",
    "    styles.add(ParagraphStyle(name='CenterTitle', alignment=TA_CENTER,\n",
    "                              fontSize=16, leading=20, spaceAfter=10))\n",
    "    styles.add(ParagraphStyle(name='Body', alignment=TA_LEFT,\n",
    "                              fontSize=10, leading=12))\n",
    "\n",
    "    flow = []\n",
    "    flow.append(Paragraph(f\"{title} — Hof University\", styles['CenterTitle']))\n",
    "    flow.append(Paragraph(f\"Source: {url}\", styles['Body']))\n",
    "    flow.append(Spacer(1, 8))\n",
    "\n",
    "    for para in clean_text.split(\"\\n\\n\"):\n",
    "        wrapped = \"\\n\".join(textwrap.fill(line, 95) for line in para.splitlines())\n",
    "        flow.append(Paragraph(wrapped.replace(\"\\n\", \"<br/>\"), styles['Body']))\n",
    "        flow.append(Spacer(1, 4))\n",
    "\n",
    "    doc.build(flow)\n",
    "    print(f\"✅ PDF created: {pdf_path}\")\n",
    "\n",
    "# ---------- RUN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    link = input(\"Enter webpage URL: \").strip()\n",
    "    create_clean_pdf(link)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
